{"cells":[{"cell_type":"code","execution_count":46,"metadata":{"id":"JXbMh1e_l8Pu","executionInfo":{"status":"ok","timestamp":1687073048553,"user_tz":-330,"elapsed":651,"user":{"displayName":"Bhoomika 19bec7146","userId":"16889730182528431808"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LayerNormalization, PReLU, Conv1D, Conv2D, Input, Concatenate, Activation, Multiply, Add\n","from tensorflow.keras.layers import GRU, Reshape\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.activations import sigmoid\n","#print(tf.__version__)\n","\n","def DilatedDenseBlock(inputs):\n","        lnz0= model.add(LayerNormalization())\n","        prl0 = model.add(PReLU())\n","        c1 = model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=1, dilation_rate=1, padding='same'))\n","        x0= Concatenate([inputs, c1])\n","\n","        lnz1= model.add(LayerNormalization())\n","        prl1 = model.add(PReLU())\n","        c2 = model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=1, dilation_rate=2, padding='same'))\n","        x1= Concatenate([inputs, c2, x0])\n","\n","        lnz2= model.add(LayerNormalization())\n","        prl2 = model.add(PReLU())\n","        c3 = model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=1, dilation_rate=4, padding='same'))\n","        x2= Concatenate([inputs, c3, x1, x0])\n","\n","        lnz3= model.add(LayerNormalization())\n","        prl3 = model.add(PReLU())\n","        c4 = model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=1, dilation_rate=8, padding='same'))\n","        x3= Concatenate([inputs, c4, x2, x1, x0])\n","\n","        lnz4= model.add(LayerNormalization())\n","        prl4 = model.add(PReLU())\n","        c5 = model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=1, dilation_rate=16, padding='same'))\n","        x4= Concatenate([inputs, c5, x3, x2, x1, x0])\n","        return x4\n","\n","def SqueezedTemporalConvolutionalModule(inputs):\n","       convn1= Conv1D(64, kernel_size=1, strides=1, activation='relu', padding='same')(inputs)\n","       #main branch\n","       mb_prelu1 = PReLU()(convn1)\n","       mb_norm1 = LayerNormalization()(mb_prelu1)\n","       mb_dc1 = Conv2D(filters=64, kernel_size=(3,3), dilation_rate=1, padding='same')(mb_norm1)\n","       #gate branch\n","       gb_prelu1 = PReLU()(convn1)\n","       gb_norm1 = LayerNormalization()(gb_prelu1)\n","       gb_dc1 = Conv2D(filters=64, kernel_size=(3,3), activation='sigmoid', dilation_rate=1, padding='same')(gb_norm1)\n","       #multiplicative gate\n","       gated_main_branch1 = Multiply()([mb_dc1, gb_dc1])\n","       prelu1 = PReLU()(gated_main_branch1)\n","       norm1 = LayerNormalization()(prelu1)\n","       convn2= Conv1D(256, kernel_size=1,strides=1, activation='relu',padding='same')(norm1)\n","       #additive gate\n","       a1=Add()([convn2, inputs])\n","       #--------------------------\n","       convn3 = Conv1D(64, kernel_size=1,strides=1, activation='relu',padding='same')(a1)\n","       mb_prelu2 = PReLU()(convn3)\n","       mb_norm2 = LayerNormalization()(mb_prelu2)\n","       mb_dc2 = Conv2D(filters=64, kernel_size=(3,3), dilation_rate=2, padding='same')(mb_norm2)\n","       gb_prelu2 = PReLU()(a1)\n","       gb_norm2 = LayerNormalization()(gb_prelu2)\n","       gb_dc2 = Conv2D(filters=64, kernel_size=(3,3), activation='sigmoid', dilation_rate=2, padding='same')(gb_norm2)\n","       gated_main_branch2 =Multiply()([mb_dc2, gb_dc2])\n","       prelu2 = PReLU()(gated_main_branch2)\n","       norm2 = LayerNormalization()(prelu2)\n","       convn4= Conv1D(256, kernel_size=1,strides=1, activation='relu',padding='same')(norm2)\n","       a2=Add()([convn4, a1])\n","       #-----------------------------\n","       convn5 = Conv1D(64, kernel_size=1,strides=1, activation='relu',padding='same')(a2)\n","       mb_prelu3 = PReLU()(convn5)\n","       mb_norm3 = LayerNormalization()(mb_prelu3)\n","       mb_dc3 = Conv2D(filters=64, kernel_size=(3,3), dilation_rate=4, padding='same')(mb_norm3)\n","       gb_prelu3 = PReLU()(a2)\n","       gb_norm3 = LayerNormalization()(gb_prelu3)\n","       gb_dc3 = Conv2D(filters=64, kernel_size=(3,3), activation='sigmoid', dilation_rate=4, padding='same')(gb_norm3)\n","       gated_main_branch3 = Multiply()([mb_dc3, gb_dc3])\n","       prelu3 = PReLU()(gated_main_branch3)\n","       norm3 = LayerNormalization()(prelu3)\n","       convn6= Conv1D(256, kernel_size=1,strides=1, activation='relu',padding='same')(norm3)\n","       a3=Add()([convn6, a2])\n","       #-----------------------------\n","       convn7 = Conv1D(64, kernel_size=1,strides=1, activation='relu',padding='same')(a3)\n","       mb_prelu4 = PReLU()(convn7)\n","       mb_norm4 = LayerNormalization()(mb_prelu4)\n","       mb_dc4 = Conv2D(filters=64, kernel_size=(3,3), dilation_rate=8, padding='same')(mb_norm4)\n","       gb_prelu4 = PReLU()(a3)\n","       gb_norm4 = LayerNormalization()(gb_prelu4)\n","       gb_dc4 =Conv2D(filters=64, kernel_size=(3,3), activation='sigmoid', dilation_rate=8, padding='same')(gb_norm4)\n","       gated_main_branch4 = Multiply()([mb_dc4, gb_dc4])\n","       prelu4 = PReLU()(gated_main_branch4)\n","       norm4 = LayerNormalization()(prelu4)\n","       convn8= Conv1D(256, kernel_size=1,strides=1, activation='relu',padding='same')(norm4)\n","       a4=Add()([convn8, a3])\n","       #-----------------------------\n","       convn9 = Conv1D(64, kernel_size=1,strides=1, activation='relu',padding='same')(a4)\n","       mb_prelu5 = PReLU()(convn9)\n","       mb_norm5 =LayerNormalization()(mb_prelu5)\n","       mb_dc5 =Conv2D(filters=64, kernel_size=(3,3), dilation_rate=16, padding='same')(mb_norm5)\n","       gb_prelu5 = PReLU()(a4)\n","       gb_norm5 = LayerNormalization()(gb_prelu5)\n","       gb_dc5 =Conv2D(filters=64, kernel_size=(3,3), activation='sigmoid', dilation_rate=16, padding='same')(gb_norm5)\n","       gated_main_branch5 = Multiply()([mb_dc5, gb_dc5])\n","       prelu5 =PReLU()(gated_main_branch5)\n","       norm5 = LayerNormalization()(prelu5)\n","       convn10= Conv1D(256, kernel_size=1,strides=1, activation='relu',padding='same')(norm5)\n","       a5=Add()([convn10, a4])\n","       return a5\n","\n","def unet(pretrained_weights = None,input_size = (128,128,1)):\n","    input_size = (128,128,1)\n","    #size_filter_in = 16\n","    #normal initialization of weights\n","    kernel_init = 'he_normal'\n","    #To apply leaky relu after the conv layer\n","    activation_layer = None\n","    inputs = Input(input_size)\n","    model= Sequential()\n","    #2D convolutional layer with 64 filters(it was taken for all the convolutions in the research paper), a kernel size of (3, 3),'same' padding\n","    conv1= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln1=model.add(LayerNormalization())\n","    act1=model.add(PReLU())\n","    mp1=model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    db1 =DilatedDenseBlock(mp1)\n","    stcm1=SqueezedTemporalConvolutionalModule(db1)\n","\n","    conv2= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln2=model.add(LayerNormalization())\n","    act2=model.add(PReLU())\n","    mp2=model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    db2 =DilatedDenseBlock(mp2)\n","    stcm2=SqueezedTemporalConvolutionalModule(db2)\n","\n","    conv3= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln3=model.add(LayerNormalization())\n","    act3=model.add(PReLU())\n","    mp3=model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    db3 = DilatedDenseBlock(mp3)\n","    stcm3=SqueezedTemporalConvolutionalModule(db3)\n","\n","    conv4= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln4=model.add(LayerNormalization())\n","    act4=model.add(PReLU())\n","    mp4=model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n","    db4 = DilatedDenseBlock(mp4)\n","    stcm4=SqueezedTemporalConvolutionalModule(db4)\n","\n","    # Reshape and add GRU layers\n","    r1=model.add(tf.keras.layers.Reshape(target_shape=(64, -1)))\n","\n","    gru1=model.add(tf.keras.layers.GRU(units=160, return_sequences=True))\n","    gru2=model.add(tf.keras.layers.GRU(units=320, return_sequences=False))\n","\n","    r2=model.add(tf.keras.layers.Reshape(target_shape=(8,8,5)))\n","\n","    conv5= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln5=model.add(LayerNormalization())\n","    act5=model.add(PReLU())\n","\n","    #Upsampling2D layer with size of 2x2\n","    ups1=model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n","    db5 =DilatedDenseBlock(ups1)\n","    stcm5=SqueezedTemporalConvolutionalModule(db5)\n","\n","    conv6= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln6=model.add(LayerNormalization())\n","    act6=model.add(PReLU())\n","    ups2=model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n","    db6 =DilatedDenseBlock(ups2)\n","    stcm6=SqueezedTemporalConvolutionalModule(db6)\n","\n","    conv7= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln7=model.add(LayerNormalization())\n","    act7=model.add(PReLU())\n","    ups3=model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n","    db7 =DilatedDenseBlock(ups3)\n","    stcm7=SqueezedTemporalConvolutionalModule(db7)\n","\n","    conv8= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same'))\n","    ln8=model.add(LayerNormalization())\n","    act8=model.add(PReLU())\n","    ups4=model.add(tf.keras.layers.UpSampling2D(size=(2, 2)))\n","    db8 =DilatedDenseBlock(ups4)\n","    stcm8=SqueezedTemporalConvolutionalModule(db8)\n","\n","    # Final convolution layer\n","    conv9= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='softmax'))\n","    ln9=model.add(LayerNormalization())\n","    act9=model.add(PReLU())\n","\n","    conv10= model.add(tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='softmax'))\n","    # build model\n","    model.build(input_size)\n","\n","    #Print the model summary\n","    model.summary()\n","\n","    model.compile(optimizer = 'adam', loss = tf.keras.losses.Huber(), metrics = ['mae'])\n","\n","    if(pretrained_weights):\n","       model.load_weights(pretrained_weights)\n","    return model\n",""]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP6+HypPuNcJJ0ivVW7P0Ad"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}